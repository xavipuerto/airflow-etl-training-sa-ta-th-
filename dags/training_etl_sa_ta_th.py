#!/usr/bin/env python3
"""
Training DAG: ETL Architecture with SA-TA-TH Pattern
====================================================

This DAG demonstrates a complete ETL flow using public APIs

ğŸ¯ LEARNING OBJECTIVE:
Teach the SA-TA-TH layered architecture in an ETL process

ğŸ“š KEY CONCEPTS:
- SA (Staging Area): Landing zone with TRUNCATE+INSERT
- TA (Auxiliary Tables): For joins and high-volume transformations (not used in this simple example)
- TH (Historical Tables): Persistence layer with MERGE or INSERT append-only

ğŸ”„ WORKFLOW:
1. Get All Countries: API /all â†’ SA + TH (Complete ETL with MERGE)
2. Get Regions Stats: API /region/{region} â†’ Aggregation â†’ SA + TH (with MERGE)
3. Get Air Quality: API /measurements â†’ SA + TH (time series, INSERT append-only)

ğŸ“Š DATA SOURCES:
- REST Countries API: https://restcountries.com/ (countries data)
- AQICN API: https://aqicn.org/api/ (air quality & weather)

ğŸ’¡ USE CASES:
- Master data with slow changes (countries) â†’ MERGE
- Aggregations and statistics â†’ MERGE
- Time series (air quality) â†’ INSERT append-only (prepared for TimescaleDB)
- JOIN between different sources (countries + air quality)
"""
from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
import sys

# Add scripts to path
sys.path.insert(0, '/opt/airflow/scripts')

# Import ETL functions (functional scripts) - Multiple SA tables
from training_get_countries_basic import etl_get_countries_basic
from training_get_countries_geo import etl_get_countries_geo
from training_get_countries_culture import etl_get_countries_culture
from training_merge_countries_to_th import etl_merge_countries_to_th
from training_get_regions_stats import etl_get_regions_stats
from training_get_weather import etl_get_weather_data
from training_get_air_quality_aqicn import etl_get_air_quality


# =============================================================================
# DAG CONFIGURATION
# =============================================================================

default_args = {
    'owner': 'training',
    'depends_on_past': False,
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=5),
}

dag = DAG(
    dag_id='training_etl_sa_ta_th',
    default_args=default_args,
    description='ğŸ“ Training: ETL with SA-TA-TH architecture using REST Countries API',
    schedule=timedelta(minutes=5),  # Run every 5 minutes
    start_date=datetime(2026, 2, 1),
    catchup=False,
    tags=['training', 'etl', 'sa-ta-th', 'rest-countries'],
)


# =============================================================================
# WRAPPERS FOR AIRFLOW
# =============================================================================

def wrapper_get_countries_basic(**context):
    """
    Wrapper for ETL: Get Countries BASIC
    
    Executes loading of basic fields: API /all (8 fields) â†’ SA basic
    """
    execution_id = context['run_id']
    print(f"ğŸ¯ Execution ID: {execution_id}")
    
    stats = etl_get_countries_basic(execution_id=execution_id)
    context['task_instance'].xcom_push(key='countries_basic_stats', value=stats)
    
    print(f"âœ… Countries BASIC ETL completed: {stats['rows_inserted_sa']} countries")
    return stats


def wrapper_get_countries_geo(**context):
    """
    Wrapper for ETL: Get Countries GEO
    
    Executes loading of geographic fields: API /all (5 fields) â†’ SA geo
    """
    execution_id = context['run_id']
    print(f"ğŸ¯ Execution ID: {execution_id}")
    
    stats = etl_get_countries_geo(execution_id=execution_id)
    context['task_instance'].xcom_push(key='countries_geo_stats', value=stats)
    
    print(f"âœ… Countries GEO ETL completed: {stats['rows_inserted_sa']} countries")
    return stats


def wrapper_get_countries_culture(**context):
    """
    Wrapper for ETL: Get Countries CULTURE
    
    Executes loading of cultural/political fields: API /all (9 fields) â†’ SA culture
    """
    execution_id = context['run_id']
    print(f"ğŸ¯ Execution ID: {execution_id}")
    
    stats = etl_get_countries_culture(execution_id=execution_id)
    context['task_instance'].xcom_push(key='countries_culture_stats', value=stats)
    
    print(f"âœ… Countries CULTURE ETL completed: {stats['rows_inserted_sa']} countries")
    return stats


def wrapper_merge_countries_to_th(**context):
    """
    Wrapper for ETL: Merge Countries SA â†’ TH
    
    Combines 3 SA tables (basic + geo + culture) and performs MERGE into TH
    """
    execution_id = context['run_id']
    print(f"ğŸ¯ Execution ID: {execution_id}")
    
    stats = etl_merge_countries_to_th(execution_id=execution_id)
    context['task_instance'].xcom_push(key='countries_merged_stats', value=stats)
    
    print(f"âœ… MERGE completed: {stats['countries_inserted']} new, {stats['countries_updated']} updated")
    return stats


def wrapper_get_regions_stats(**context):
    """
    Wrapper for ETL: Get Regions Statistics
    
    Executes complete flow: API /region/{region} â†’ Aggregation â†’ SA â†’ TH
    """
    execution_id = context['run_id']
    print(f"ğŸ¯ Execution ID: {execution_id}")
    
    stats = etl_get_regions_stats(execution_id=execution_id)
    
    if not stats['success']:
        raise Exception(f"âŒ ETL Get Regions Stats failed: {stats['errors']}")
    
    # Save statistics to XCom
    context['task_instance'].xcom_push(key='regions_stats', value=stats)
    
    print(f"âœ… ETL completed:")
    print(f"   ğŸ“¥ Regions processed: {', '.join(stats['regions_processed'])}")
    print(f"   ğŸ“Š Countries extracted: {stats['countries_extracted']}")
    print(f"   ğŸ’¾ SA loaded: {stats['sa_loaded']}")
    print(f"   ğŸ“¥ TH inserted: {stats['th_inserted']}")
    print(f"   ğŸ”„ TH updated: {stats['th_updated']}")
    
    return stats


def wrapper_get_weather(**context):
    """
    Wrapper for ETL: Get Weather Data
    
    Executes complete flow: API /forecast â†’ SA â†’ TH (append-only)
    Time series of weather data
    """
    execution_id = context['run_id']
    print(f"ğŸ¯ Execution ID: {execution_id}")
    
    stats = etl_get_weather_data(execution_id=execution_id)
    
    if not stats['success']:
        raise Exception(f"âŒ ETL Get Weather Data failed: {stats['errors']}")
    
    # Save statistics to XCom
    context['task_instance'].xcom_push(key='weather_stats', value=stats)
    
    print(f"âœ… ETL completed:")
    print(f"   ğŸ“¥ Cities processed: {', '.join(stats['countries_processed'])}")
    print(f"   ğŸ“Š Measurements extracted: {stats['measurements_extracted']}")
    print(f"   ğŸ’¾ SA loaded: {stats['sa_loaded']}")
    print(f"   ğŸ“¥ TH inserted: {stats['th_inserted']}")
    print(f"   ğŸ”„ Duplicates ignored: {stats['th_duplicates']}")
    print(f"   ğŸ“Š Total in TH: {stats['th_total']}")
    
    return stats


def wrapper_get_air_quality(**context):
    """
    Wrapper para ETL: Get Air Quality from AQICN (World Air Quality Index)
def wrapper_get_air_quality(**context):
    """
    Wrapper for ETL: Get Air Quality from AQICN (World Air Quality Index)
    
    Executes complete flow: AQICN API â†’ SA â†’ TH (append-only)
    Time series of air quality data from capitals in th_training_countries
    """
    execution_id = context['run_id']
    print(f"ğŸ¯ Execution ID: {execution_id}")
    
    stats = etl_get_air_quality(execution_id=execution_id)
    
    if stats.get('status') != 'SUCCESS':
        raise Exception(f"âŒ ETL Get Air Quality failed: {stats.get('status', 'UNKNOWN')}")
    
    # Save statistics to XCom
    context['task_instance'].xcom_push(key='air_quality_stats', value=stats)
    
    print(f"âœ… ETL completed:")
    print(f"   ğŸ“Š Measurements extracted: {stats['measurements_extracted']}")
    print(f"   ğŸ’¾ SA loaded: {stats['rows_in_sa']}")
    print(f"   ğŸ“¥ TH inserted: {stats['th_inserted']}")
    print(f"   ğŸ”„ Duplicates ignored: {stats['th_duplicates']}")
    print(f"   ğŸ“Š Total in TH: {stats['th_total']}")
    
    return stats


# =============================================================================
# DEFINICIÃ“N DE TAREAS
# =============================================================================

# Tarea 1a: Get Countries BASIC (campos bÃ¡sicos)
task_get_countries_basic = PythonOperator(
    task_id='get_countries_basic',
    python_callable=wrapper_get_countries_basic,
    dag=dag,
    doc_md="""
    ## ğŸŒ Get Countries BASIC (Paso 1/4)
    
    **Objetivo:** Cargar campos BÃSICOS de todos los paÃ­ses
    
    **Endpoint:** `GET /all?fields=cca2,cca3,name,capital,region,subregion,area,population`
    
    **Flujo:**
    1. EXTRACT: Llamar API (8 campos)
    2. TRANSFORM: Normalizar nombres y estructuras
    3. LOAD SA: TRUNCATE + INSERT en sa_training_countries_basic
    
    **Tabla destino:** `ga_integration.sa_training_countries_basic`
    
    **Por quÃ© separado?**
    - La API REST Countries limita a 10 campos por request
    - Dividimos en 3 tipos de campos: basic, geo, culture
    - Permite paralelizar las 3 extracciones
    - PatrÃ³n educativo: mÃºltiples SA â†’ 1 TH
    """,
)

# Tarea 1b: Get Countries GEO (campos geogrÃ¡ficos)
task_get_countries_geo = PythonOperator(
    task_id='get_countries_geo',
    python_callable=wrapper_get_countries_geo,
    dag=dag,
    doc_md="""
    ## ğŸ—ºï¸  Get Countries GEO (Paso 2/4)
    
    **Objetivo:** Cargar campos GEOGRÃFICOS de todos los paÃ­ses
    
    **Endpoint:** `GET /all?fields=cca2,cca3,latlng,landlocked,borders`
    
    **Flujo:**
    1. EXTRACT: Llamar API (5 campos)
    2. TRANSFORM: Normalizar coordenadas y fronteras
    3. LOAD SA: TRUNCATE + INSERT en sa_training_countries_geo
    
    **Tabla destino:** `ga_integration.sa_training_countries_geo`
    
    **Datos interesantes:**
    - landlocked: paÃ­ses sin salida al mar (Suiza, Bolivia, etc.)
    - borders: lista de paÃ­ses fronterizos (JSON array)
    - latlng: coordenadas para mapas
    """,
)

# Tarea 1c: Get Countries CULTURE (campos culturales/polÃ­ticos)
task_get_countries_culture = PythonOperator(
    task_id='get_countries_culture',
    python_callable=wrapper_get_countries_culture,
    dag=dag,
    doc_md="""
    ## ğŸ­ Get Countries CULTURE (Paso 3/4)
    
    **Objetivo:** Cargar campos CULTURALES/POLÃTICOS de todos los paÃ­ses
    
    **Endpoint:** `GET /all?fields=cca2,cca3,languages,currencies,timezones,flags,independent,unMember,ccn3`
    
    **Flujo:**
    1. EXTRACT: Llamar API (9 campos)
    2. TRANSFORM: Normalizar idiomas, monedas, zonas horarias
    3. LOAD SA: TRUNCATE + INSERT en sa_training_countries_culture
    
    **Tabla destino:** `ga_integration.sa_training_countries_culture`
    
    **Datos interesantes:**
    - languages: idiomas oficiales (JSON object)
    - currencies: monedas (JSON object)
    - timezones: zonas horarias (JSON array)
    - independent: si es paÃ­s independiente
    - unMember: si es miembro de la ONU
    """,
)

# Tarea 1d: Merge Countries (combinar 3 SA â†’ TH)
task_merge_countries_to_th = PythonOperator(
    task_id='merge_countries_to_th',
    python_callable=wrapper_merge_countries_to_th,
    dag=dag,
    doc_md="""
    ## ğŸ”— Merge Countries SA â†’ TH (Paso 4/4 - FINAL)
    
    **Objetivo:** Combinar 3 Staging Areas y hacer MERGE en TH
    
    **Fuentes:**
    - sa_training_countries_basic (8 campos)
    - sa_training_countries_geo (5 campos)
    - sa_training_countries_culture (9 campos)
    
    **Flujo:**
    1. READ: JOIN de las 3 SA por code_iso3
    2. MERGE TH: UPSERT en th_training_countries (22 campos totales)
    
    **Tabla destino:** `ga_integration.th_training_countries`
    
    **ğŸ¯ CONCEPTO ETL AVANZADO:**
    Este patrÃ³n demuestra:
    - MÃºltiples SA â†’ 1 TH
    - JOIN de staging areas antes del MERGE
    - Enriquecimiento progresivo de datos
    - ParalelizaciÃ³n de extracciones + centralizaciÃ³n de MERGE
    
    **Ventajas:**
    - API calls en paralelo (3x mÃ¡s rÃ¡pido)
    - Cumple con lÃ­mite de 10 campos de la API
    - Todos los campos disponibles en TH
    - PatrÃ³n reutilizable para otros casos
    """,
)

# Tarea 2: Get Regions Statistics (ETL completo con agregaciÃ³n)
task_get_regions_stats = PythonOperator(
    task_id='get_regions_stats',
    python_callable=wrapper_get_regions_stats,
    dag=dag,
    doc_md="""
    ## ğŸ“Š Get Regions Statistics (ETL Completo + AgregaciÃ³n)
    
    **Objetivo:** Obtener estadÃ­sticas agregadas por regiÃ³n geogrÃ¡fica
    
    **Endpoint:** `GET /region/{region}` (mÃºltiples llamadas)
    
    **Regiones:** africa, americas, asia, europe, oceania
    
    **Flujo:**
    1. EXTRACT: Llamar a API /region/{region} para cada regiÃ³n
    2. TRANSFORM: Calcular agregaciones (COUNT, SUM, AVG)
       - Total paÃ­ses por regiÃ³n
       - PoblaciÃ³n total y promedio
       - Ãrea total
       - Conteo de paÃ­ses landlocked, independientes, miembros ONU
    3. LOAD SA: TRUNCATE + INSERT en sa_training_regions_stats
    4. MERGE TH: UPSERT en th_training_regions_stats
    
    **Tablas afectadas:**
    - `ga_integration.sa_training_regions_stats` (SA - TRUNCATE+INSERT)
    - `ga_integration.th_training_regions_stats` (TH - UPSERT)
    
    **Por quÃ© este enfoque?**
    - Demuestra agregaciones y transformaciones complejas
    - MÃºltiples llamadas a API con parÃ¡metros diferentes
    - CÃ¡lculo de mÃ©tricas derivadas
    """,
)

# Tarea 3: Get Weather Data (ETL completo - Series Temporales)
task_get_weather = PythonOperator(
    task_id='get_weather',
    python_callable=wrapper_get_weather,
    dag=dag,
    doc_md="""
    ## ğŸŒ¤ï¸ Get Weather Data (ETL Series Temporales)
    
    **Objetivo:** Obtener datos meteorolÃ³gicos de capitales de paÃ­ses
    
    **Endpoint:** `GET /forecast` (Open-Meteo API)
    
    **Fuente:** https://open-meteo.com/ (API pÃºblica gratuita, sin API key)
    
    **Flujo:**
    1. EXTRACT: Llamar a API /forecast para 10 capitales
       - Datos: temperatura, humedad, precipitaciÃ³n, viento
    2. TRANSFORM: Normalizar timestamps y valores
    3. LOAD SA: TRUNCATE + INSERT en sa_training_weather
    4. LOAD TH: INSERT append-only en th_training_weather
    
    **Tablas afectadas:**
    - `ga_integration.sa_training_weather` (SA - TRUNCATE+INSERT)
    - `ga_integration.th_training_weather` (TH - INSERT append-only)
    
    **Diferencias con otras tareas:**
    - âœ… Series temporales (timestamp como partition key)
    - âœ… Estrategia append-only (INSERT, no MERGE)
    - âœ… Constraint UNIQUE para evitar duplicados
    - âœ… Preparada para TimescaleDB hypertables
    - âœ… JOIN con paÃ­ses (country code)
    
    **Por quÃ© append-only?**
    - Cada mediciÃ³n es un punto Ãºnico en el tiempo
    - No tiene sentido "actualizar" una mediciÃ³n pasada
    - Optimizado para queries de series temporales
    - Compatible con TimescaleDB
    """,
)

# Tarea 4: Get Air Quality (ETL completo - Series Temporales AQICN)
task_get_air_quality = PythonOperator(
    task_id='get_air_quality',
    python_callable=wrapper_get_air_quality,
    dag=dag,
    doc_md=""" ## ğŸŒ«ï¸ Get Air Quality Data (ETL Series Temporales - AQICN)
    
    **Objetivo:** Obtener datos de calidad del aire en tiempo real
    
    **Fuente:** World Air Quality Index (AQICN) - https://aqicn.org/api/
    
    **Ciudades monitoreadas:** beijing, shanghai, delhi, london, paris, madrid, new-york, los-angeles, tokyo, seoul
    
    **Flujo:**
    1. EXTRACT: Llamar a AQICN API /feed/{city} para 10 ciudades
       - Datos: AQI, PM2.5, PM10, O3, NO2, SO2, CO, temperatura, humedad
    2. TRANSFORM: Normalizar timestamps y valores
    3. LOAD SA: TRUNCATE + INSERT en sa_training_air_quality
    4. LOAD TH: INSERT append-only en th_training_air_quality
    
    **Tablas afectadas:**
    - `ga_integration.sa_training_air_quality` (SA - TRUNCATE+INSERT)
    - `ga_integration.th_training_air_quality` (TH - INSERT append-only)
    
    **CaracterÃ­sticas:**
    - âœ… API gratuita con 1,000 req/s quota
    - âœ… Token-based authentication (AQICN_API_TOKEN)
    - âœ… Datos en tiempo real de estaciones oficiales
    - âœ… Series temporales con append-only pattern
    - âœ… Constraint UNIQUE (measured_at, station_id)
    - âœ… Ãndice temporal para queries eficientes
    
    **MÃ©tricas monitoreadas:**
    - AQI: Air Quality Index (0-500)
    - PM2.5, PM10: PartÃ­culas en suspensiÃ³n
    - O3, NO2, SO2, CO: Gases contaminantes
    - Temperatura, humedad, presiÃ³n atmosfÃ©rica
    
    **InterpretaciÃ³n AQI:**
    - 0-50: Good (Verde)
    - 51-100: Moderate (Amarillo)
    - 101-150: Unhealthy for Sensitive Groups (Naranja)
    - 151-200: Unhealthy (Rojo)
    - 201-300: Very Unhealthy (PÃºrpura)
    - 301+: Hazardous (MarrÃ³n)
    """,
)

# =============================================================================
# DEPENDENCIAS
# =============================================================================

# Flujo completo:
# 1. Extraer 3 tipos de campos en paralelo (basic, geo, culture)
# 2. Combinar las 3 SA en TH (merge)
# 3. Ejecutar regions y weather en paralelo (usan datos de TH countries)

# PASO 1: Extracciones en paralelo (3 API calls simultÃ¡neos)
[task_get_countries_basic, task_get_countries_geo, task_get_countries_culture] >> task_merge_countries_to_th

# PASO 2: DespuÃ©s del MERGE, ejecutar aggregaciones y series temporales en paralelo
task_merge_countries_to_th >> [task_get_regions_stats, task_get_weather, task_get_air_quality]

# Esto crea este grafo:
#
#    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#    â”‚get_countries    â”‚
#    â”‚   _basic        â”‚
#    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#             â”‚
#    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”
#    â”‚get_countries    â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#    â”‚   _geo          â”‚â”€â”€â”€â”€â”€â”€â”€â†’â”‚merge_        â”‚
#    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚countries_    â”‚
#             â”‚                 â”‚to_th         â”‚
#    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
#    â”‚get_countries    â”‚               â”‚
#    â”‚   _culture      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#             
#                               â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#                               â”‚             â”‚              â”‚
#                        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#                        â”‚get_regions  â”‚ â”‚get_weather  â”‚ â”‚get_air     â”‚
#                        â”‚   _stats    â”‚ â”‚             â”‚ â”‚  _quality  â”‚
#                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#
# Ventajas:
# 1. ParalelizaciÃ³n mÃ¡xima: 3 API calls simultÃ¡neos para countries
# 2. Cumple lÃ­mite de 10 campos de REST Countries API
# 3. Todos los campos disponibles (22 campos totales)
# 4. PatrÃ³n educativo: mÃºltiples SA â†’ 1 TH â†’ mÃºltiples anÃ¡lisis
# 5. Optimiza tiempo total de ejecuciÃ³n
# 6. MÃºltiples fuentes de datos: REST Countries, Open-Meteo, AQICN


# =============================================================================
# DOCUMENTACIÃ“N DEL DAG
# =============================================================================

dag.doc_md = """
# ğŸ“ DAG de FormaciÃ³n: Arquitectura ETL con SA-TA-TH

## ğŸ¯ Objetivo Educativo

Este DAG enseÃ±a la arquitectura de capas **SA-TA-TH** usando **scripts funcionales**
que agrupan el cÃ³digo por objetivo de negocio (endpoint de la API).

## ğŸ—ï¸ Arquitectura: Scripts Funcionales

En vez de separar por capa tÃ©cnica (SA vs TH), organizamos por **objetivo funcional**:

### Enfoque Tradicional (NO usado aquÃ­):
```
scripts/
  â”œâ”€â”€ extract_sa.py      â† Maneja solo SA
  â”œâ”€â”€ merge_th.py        â† Maneja solo TH
```

### Enfoque Funcional (USADO aquÃ­):
```
scripts/
  â”œâ”€â”€ training_get_all_countries.py      â† GET /all (SA + TH completo)
  â”œâ”€â”€ training_get_regions_stats.py      â† GET /region/{} (SA + TH + agregaciÃ³n)
```

**Ventajas:**
- âœ… Un script = un objetivo completo (cohesiÃ³n)
- âœ… FÃ¡cil de testear independientemente
- âœ… Menor acoplamiento entre componentes
- âœ… MÃ¡s fÃ¡cil de mantener y extender

## ğŸ“š Conceptos Clave

### SA - Staging Area (Ãrea de Aterrizaje)
- **PropÃ³sito:** Capa temporal para aterrizar datos externos
- **Estrategia:** TRUNCATE + INSERT (refresco completo)
- **CaracterÃ­sticas:**
  - Sin constraints complejos (no PKs, FKs)
  - Optimizada para carga rÃ¡pida
  - Se puede truncar sin miedo
  - Aislamiento de errores
  
### TA - Tablas Auxiliares
- **PropÃ³sito:** Tablas intermedias para:
  - VolumetrÃ­a alta que no cabe en memoria
  - Cruces complejos entre mÃºltiples fuentes
  - Agregaciones temporales
- **Nota:** No se requiere en ejemplos simples, solo cuando hay mucho volumen o cruces

### TH - Tablas HistÃ³ricas
- **PropÃ³sito:** Persistencia y consulta
- **Estrategia:** MERGE (UPSERT)
- **CaracterÃ­sticas:**
  - Constraints (PKs, FKs, Ã­ndices)
  - Control de versiones (first_loaded_at, last_updated_at, version)
  - Optimizada para consultas
  - Mantiene histÃ³rico de cambios

## ğŸ”„ Flujo del DAG

### Tarea 1: Get All Countries
```
GET /all
   â†“
[Normalize]
   â†“
sa_training_countries (TRUNCATE+INSERT)
   â†“
[MERGE]
   â†“
th_training_countries (UPSERT)
```

### Tarea 2: Get Regions Stats (Paralelo)
```
GET /region/{africa,americas,asia,europe,oceania}
   â†“
[Aggregate: COUNT, SUM, AVG]
   â†“
sa_training_regions_stats (TRUNCATE+INSERT)
   â†“
[MERGE]
   â†“
th_training_regions_stats (UPSERT)
```

## ğŸŒ Fuente de Datos

**REST Countries API:** https://restcountries.com/

- API pÃºblica, sin autenticaciÃ³n
- Datos de todos los paÃ­ses del mundo
- Ideal para formaciÃ³n y demos

## ğŸ“Š Tablas Creadas

### PaÃ­ses
- **`sa_training_countries`** - Staging de paÃ­ses (TRUNCATE+INSERT)
- **`th_training_countries`** - HistÃ³rico de paÃ­ses (UPSERT con versioning)

### EstadÃ­sticas Regionales
- **`sa_training_regions_stats`** - Staging de stats por regiÃ³n (TRUNCATE+INSERT)
- **`th_training_regions_stats`** - HistÃ³rico de stats (UPSERT con versioning)

## ğŸš€ CÃ³mo Usar

### 1. Crear Tablas (una sola vez)
```bash
# Ejecutar DDL inicial
docker exec -i airflow-postgres-1 psql -U goaigua_user -d goaigua_data < scripts/ddl_initial.sql
```

### 2. Ejecutar DAG
- Ir a Airflow UI: http://localhost:8080
- Activar DAG: `training_etl_sa_ta_th`
- Trigger manual: click en "Play" button

### 3. Ver Logs
- Click en la tarea â†’ View Log
- VerÃ¡s el output completo del ETL

## ğŸ“ Consultas Ãštiles

```sql
-- Ver todos los paÃ­ses en TH
SELECT code_iso3, name_common, region, population, version
FROM ga_integration.th_training_countries 
ORDER BY population DESC
LIMIT 10;

-- Ver paÃ­ses actualizados recientemente
SELECT code_iso3, name_common, version, last_updated_at
FROM ga_integration.th_training_countries 
WHERE version > 1
ORDER BY last_updated_at DESC;

-- Ver estadÃ­sticas por regiÃ³n
SELECT region, total_countries, total_population, avg_population
FROM ga_integration.th_training_regions_stats 
ORDER BY total_population DESC;

-- PaÃ­ses de Europa (usando vista)
SELECT * FROM ga_integration.v_countries_europe LIMIT 10;

-- Top 10 mÃ¡s poblados (usando vista)
SELECT * FROM ga_integration.v_countries_top10_population;

-- Cambios recientes (usando vista)
SELECT * FROM ga_integration.v_countries_recent_changes;
```

## ğŸ§ª Testing Independiente

Puedes ejecutar los scripts directamente para testing:

```bash
# Test: Get All Countries
docker exec -it airflow-scheduler python /opt/airflow/scripts/training_get_all_countries.py

# Test: Get Regions Stats
docker exec -it airflow-scheduler python /opt/airflow/scripts/training_get_regions_stats.py

# Test: Cliente HTTP
docker exec -it airflow-scheduler python /opt/airflow/scripts/training_rest_countries_client.py
```

## ğŸ’¡ Ejercicios Propuestos

1. **Nuevo script funcional:** Crear `training_get_country_by_code.py` para GET /alpha/{code}
2. **Agregar TA:** Si quisieras cruzar datos de paÃ­ses con otra fuente externa
3. **SCD Type 2:** Modificar TH para mantener histÃ³rico completo de cambios (no solo Ãºltima versiÃ³n)
4. **Alertas:** Detectar cambios significativos en poblaciÃ³n entre versiones
5. **Monitoring:** Agregar tarea que compare SA count vs TH count

## ğŸ“– Archivos del Proyecto

```
dags/
  â””â”€â”€ training_etl_sa_ta_th.py          â† Este DAG

scripts/
  â”œâ”€â”€ ddl_initial.sql                   â† Definiciones de tablas SA/TH
  â”œâ”€â”€ training_rest_countries_client.py â† Cliente HTTP reutilizable
  â”œâ”€â”€ training_get_all_countries.py     â† Script funcional: GET /all
  â””â”€â”€ training_get_regions_stats.py     â† Script funcional: GET /region/{region}
```

## ğŸ“– Referencias

- [Airflow Documentation](https://airflow.apache.org/)
- [REST Countries API](https://restcountries.com/)
- [PostgreSQL UPSERT](https://www.postgresql.org/docs/current/sql-insert.html#SQL-ON-CONFLICT)
- [ETL Best Practices](https://en.wikipedia.org/wiki/Extract,_transform,_load)
"""

print(f"âœ… DAG 'training_etl_sa_ta_th' cargado correctamente")
